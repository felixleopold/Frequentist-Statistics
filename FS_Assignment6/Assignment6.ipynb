{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a1c29a",
   "metadata": {
    "colab_type": "text",
    "id": "-lTF-NZxR3p8"
   },
   "source": [
    "# Assignment 6\n",
    "### Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9453749",
   "metadata": {
    "colab_type": "text",
    "id": "dHAIIUstR3p_"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be7f1f",
   "metadata": {
    "colab_type": "text",
    "id": "6tcatmpfR3qA"
   },
   "source": [
    "Course evaluations are used to obtain anonymous feedback about a course in order to improve it. However, the use of course evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. [A paper from 2005](http://www.sciencedirect.com/science/article/pii/S0272775704001165) found that instructors who are viewed to be better looking receive higher instructional ratings.\n",
    "\n",
    "In this practical we will have a look at this data, and perform multiple regression to see if there is any indication that this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2be883",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUh4vyblR3qA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as ss\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab16ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "Qtv593cbR3qE",
    "outputId": "5b33dc01-29bb-43b2-c6a5-99968a67ce4b"
   },
   "outputs": [],
   "source": [
    "courseEval = pd.read_csv('CourseEvaluations.csv')\n",
    "courseEval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db4e22",
   "metadata": {
    "colab_type": "text",
    "id": "uIFxsmp1x-PZ"
   },
   "source": [
    "### Beauty influencing score\n",
    "\n",
    "The conclusion of the paper was that the perceived beauty of the lecturer has an influence on the score given in the course evaluations. First, we will create a simple model (linear regression) between `bty_avg` and `score`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e88d8",
   "metadata": {
    "colab_type": "text",
    "id": "iL6-50AdgA1s"
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Create a linear regression model of `bty_avg` predicting `score`. \n",
    "2. Plot the data with regression line.\n",
    "3. Write down the obtained regression equation and the adjusted $R^{2}$ value.<div style=\"text-align: right\"> **3 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ef87e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7XrjGlPzMyt"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "# score is the dependent variable (response) and bty_avg is the independent (predictor)\n",
    "def print_question(question_number, sep_line_width = 78):\n",
    "    print(f\"Question {question_number}\")\n",
    "    print(sep_line_width * \"=\")\n",
    "    \n",
    "print_question(1)\n",
    "print(\"\")\n",
    "formula_string = \"score ~ bty_avg\"\n",
    "\n",
    "model = sm.formula.ols(formula=formula_string, data=courseEval)\n",
    "model_fitted = model.fit()\n",
    "\n",
    "print(model_fitted.summary())\n",
    "\n",
    "print_question(2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=courseEval, x='bty_avg', y='score')\n",
    "plt.title('score vs bty_avg')\n",
    "plt.show()\n",
    "\n",
    "print(f\"The regression equation is: score = {model_fitted.params['Intercept']:.4f} + {model_fitted.params['bty_avg']:.4f} x bty_avg\")\n",
    "print(f\"The adjusted R^2 value is {model_fitted.rsquared_adj:.4f}\")\n",
    "\n",
    "\n",
    "print_question(3)\n",
    "\n",
    "\n",
    "intercept_value = model_fitted.params['Intercept']\n",
    "slope_value = model_fitted.params['bty_avg']\n",
    "\n",
    "\n",
    "print(slope_value)\n",
    "\n",
    "print(f\"score = {intercept_value} + {slope_value} × bty_avg\")\n",
    "print()\n",
    "\n",
    "print(f\"score = {intercept_value} + {slope_value} * bty_avg\")\n",
    "print()\n",
    "\n",
    "r_squared_adjusted = model_fitted.rsquared_adj\n",
    "\n",
    "\n",
    "print(f\"Adjusted R² = {r_squared_adjusted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092a922",
   "metadata": {
    "colab_type": "text",
    "id": "r4xrZgP0gII9"
   },
   "source": [
    "### **Adding more variables and dummy coding**\n",
    "\n",
    "More variables, other than `bty_avg`, can have an impact on the `score`. But instead of looking at these variables separately, we can create a multiple regression model with more than one explanatory variable. The next variable that we will add is `gender`.\n",
    "\n",
    "The problem with the `gender` variable is that it is a nominal variable (male/female). In order to use this for regression we need to convert these levels into a numerical variable with the values 0 and 1, called an **indicator variable** (also refered to as a dummy variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1bcef",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29_lblG9gxqY"
   },
   "outputs": [],
   "source": [
    "dummy_coding = {'male': 0, 'female': 1}\n",
    "gender_dummy = courseEval['gender'].copy()\n",
    "gender_dummy = gender_dummy.replace(dummy_coding)\n",
    "courseEval['gender_dummy']=gender_dummy\n",
    "courseEval.tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4d775",
   "metadata": {
    "colab_type": "text",
    "id": "cDPlAHc7Ipnu"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "Now, the dummy coding has been applied. \n",
    "\n",
    "1. Create and fit a model with `bty_avg` and `gender_dummy` predicting the `score` variable. (Hint: you can use the + sign in the formula string to add multiple explanatory variables to your model). \n",
    "2. Again, write down the formula and the adjusted $R^{2}$. \n",
    "3. Do you think the model with gender and perceived beauty is a better model than the model with beauty alone? Justify your answer.<div style=\"text-align: right\"> **3 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd52f73",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9L3RDEAIpnu"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "print_question(1)\n",
    "\n",
    "# print(courseEval['gender_dummy'].head(10))\n",
    "\n",
    "# print(\"gender\", courseEval['gender'].head(10).tolist())\n",
    "# print(\"gender_dummy\", courseEval['gender_dummy'].head(10).tolist())\n",
    "\n",
    "\n",
    "# print(courseEval['gender_dummy'].value_counts())\n",
    "\n",
    "\n",
    "formula_multiple = \"score ~ bty_avg + gender_dummy\"\n",
    "print(formula_multiple)\n",
    "\n",
    "multiple_model = sm.formula.ols(formula=formula_multiple, data=courseEval)\n",
    "\n",
    "\n",
    "multiple_fitted = multiple_model.fit()\n",
    "\n",
    "print(multiple_fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_question(2)\n",
    "\n",
    "intercept2 = multiple_fitted.params['Intercept']\n",
    "bty_coef2 = multiple_fitted.params['bty_avg']\n",
    "gender_coef2 = multiple_fitted.params['gender_dummy']\n",
    "\n",
    "\n",
    "print(f\"score = {intercept2} + {bty_coef2} * bty_avg + {gender_coef2} * gender_dummy\")\n",
    "\n",
    "\n",
    "adj_r2_2 = multiple_fitted.rsquared_adj\n",
    "print(\"Adjusted R^2:\", adj_r2_2)\n",
    "\n",
    "print(\"\")\n",
    "print_question(3)\n",
    "\n",
    "print(\"Only Beauty, Adjusted R^2:    \",r_squared_adjusted)  \n",
    "\n",
    "print(\"Beauty + Gender, Adjusted R^2:\", adj_r2_2) \n",
    "\n",
    "print(\"It increased by:\", (adj_r2_2 - r_squared_adjusted))\n",
    "print(\"Meaning, adding gender_dummy to the model explains an additional 2.2% of variance in the score (after penalizing extra parameter)\")\n",
    "\n",
    "\n",
    "print(f\"\\nModels that add gender are slightly better than models that only look.\")\n",
    "print(f\"Because the R² value has increased by {adj_r2_2 - r_squared_adjusted}.\")\n",
    "print(f\"However, it is only in the range of slightly better models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe727872",
   "metadata": {
    "colab_type": "text",
    "id": "vH35v2uKIpn0"
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "1. Plot (in a scatterplot) `bty_avg` vs `score`, and draw 2 lines in them, one for `male` and one for the `female`. (Hint: first create two separate equations for males and females). Make sure the 2 groups and lines have different colors and add a legend so you know which color represents which group. \n",
    "2. If two professors had the same beauty score, did the `male` or `female` tend to have a higher score?<div style=\"text-align: right\"> **5 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad582c4e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29ioxLNpIpn0"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "print_question(1)\n",
    "#male\n",
    "male_data = courseEval[courseEval['gender_dummy'] == 0]\n",
    "print(\"Len male:\", len(male_data))\n",
    "\n",
    "#female\n",
    "female_data = courseEval[courseEval['gender_dummy'] == 1]\n",
    "print(\"Len Fem:\", len(female_data))\n",
    "\n",
    "\n",
    "male_formula = \"score ~ bty_avg\"\n",
    "male_model = sm.formula.ols(formula=male_formula, data=male_data)\n",
    "male_fitted = male_model.fit()\n",
    "\n",
    "male_intercept = male_fitted.params['Intercept']\n",
    "male_slope = male_fitted.params['bty_avg']\n",
    "print(f\"male score = {male_intercept} + {male_slope} * bty_avg\")\n",
    "\n",
    "\n",
    "female_formula = \"score ~ bty_avg\"\n",
    "female_model = sm.formula.ols(formula=female_formula, data=female_data)\n",
    "female_fitted = female_model.fit()\n",
    "\n",
    "female_intercept = female_fitted.params['Intercept']\n",
    "female_slope = female_fitted.params['bty_avg']\n",
    "print(f\"female score = {female_intercept} + {female_slope} * bty_avg\")\n",
    "\n",
    "\n",
    "\n",
    "#male\n",
    "plt.scatter(male_data['bty_avg'], male_data['score'], color='blue')\n",
    "\n",
    "#female\n",
    "plt.scatter(female_data['bty_avg'], female_data['score'], color='red')\n",
    "\n",
    "x_values = range(1, 9) \n",
    "\n",
    "male_line_y = []\n",
    "for x in x_values:\n",
    "    y = male_intercept + male_slope * x\n",
    "    male_line_y.append(y)\n",
    "\n",
    "plt.plot(x_values, male_line_y, color='blue', linewidth=2, label='Male Line')\n",
    "  \n",
    "female_line_y = []\n",
    "for x in x_values:\n",
    "    y = female_intercept + female_slope * x\n",
    "    female_line_y.append(y)\n",
    "\n",
    "plt.plot(x_values, female_line_y, color='red', linewidth=2, label='Female Line')\n",
    "\n",
    "\n",
    "plt.xlabel('Beauty Average')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Beauty vs Score by Gender')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print_question(2)\n",
    "\n",
    "#male\n",
    "print(f\"male score = {male_intercept} + {male_slope} * bty_avg\")\n",
    "#female\n",
    "print(f\"female score = {female_intercept} + {female_slope} * bty_avg\")\n",
    "\n",
    "\n",
    "beauty_scores = [3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "for beauty in beauty_scores:\n",
    "\n",
    "    male_score = male_intercept + male_slope * beauty\n",
    "    female_score = female_intercept + female_slope * beauty\n",
    "    \n",
    "    #print(beauty)\n",
    "    #print(male_score)\n",
    "    #print(female_score)\n",
    "    \n",
    "    if female_score > male_score:\n",
    "        print(f\"female beauty score {beauty} = {female_score - male_score}\")\n",
    "    else:\n",
    "        print(f\"male beauty score {beauty} = {male_score - female_score}\")\n",
    "\n",
    "\n",
    "test_beauty = 5\n",
    "male_test = male_intercept + male_slope * test_beauty\n",
    "female_test = female_intercept + female_slope * test_beauty\n",
    "\n",
    "if female_test > male_test:\n",
    "    print(\"female tends to be higher score\")\n",
    "    print(f\"{female_test - male_test}\")\n",
    "else:\n",
    "    print(\"male tends to be higher score\")\n",
    "    print(f\"{male_test - female_test}\")\n",
    "\n",
    "print()\n",
    "print(\"When comparing the scores of women and men when the appearance scores were the same\")\n",
    "print(\"it was found that men had higher rating scores\")\n",
    "print(f\"beauuse the difference is about\", {male_test - female_test}, \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b0dd0",
   "metadata": {
    "colab_type": "text",
    "id": "JKPAK-Jrje9U"
   },
   "source": [
    "## Exercise 4\n",
    "P-values and parameter estimates should only be trusted if the conditions for the regression are reasonable. Verify that the conditions for this model are reasonable using diagnostic plots. To check the model conditions you will need to make the following plots (see page 271 of the book for more details about assumptions and example plots): \n",
    "1. scatterplot of the (absolute value) residuals (y-axis) against the predicted values (x-axis)\n",
    "2. a histogram and QQ-plot of the residuals\n",
    "3. scatterplot of the residuals (y-axis) against the order of collection (x-axis) \n",
    "4. scatterplots of the residuals (y-axis) against each of the explanatory variables (x-axis)\n",
    "\n",
    "Make sure you use subplots (plt.subplot) to order these plots in a structured  manner. All plots must have a title and labels for the x and y-axis.\n",
    "\n",
    "5. For each of the plots, describe whether the assumptions of multiple regression are met, or not.<div style=\"text-align: right\"> **9 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "print_question(1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted = multiple_fitted.fittedvalues  \n",
    "residuals = multiple_fitted.resid        \n",
    "\n",
    "\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "\n",
    "print(predicted.head(10))\n",
    "print(residuals.head(10))\n",
    "\n",
    "\n",
    "print(abs_residuals.head(10))\n",
    "\n",
    "\n",
    "plt.scatter(predicted, abs_residuals)\n",
    "\n",
    "plt.xlabel(\"predicted score\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"predicted vs residuals\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print_question(2)\n",
    "from scipy.stats import probplot\n",
    "\n",
    "print(residuals.head())\n",
    "\n",
    "#histogram \n",
    "plt.hist(residuals)\n",
    "plt.xlabel(\"residuals\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.grid()\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "\n",
    "#QQ-plot\n",
    "\n",
    "probplot(residuals, dist=\"norm\", plot=plt)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "print_question(3)\n",
    "\n",
    "\n",
    "order_of_collection = range(len(residuals))\n",
    "print(f\"{len(residuals)}\")\n",
    "print(f\"{len(residuals)-1}\")\n",
    "\n",
    "plt.scatter(order_of_collection, residuals)\n",
    "plt.xlabel(\"order_of_collection\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"residuals vs order\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print_question(4)\n",
    "\n",
    "# bty_avg vs residuals\n",
    "plt.scatter(courseEval['bty_avg'], residuals)\n",
    "plt.xlabel(\"bty_avg\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"residuals vs bty_avg\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# gender_dummy vs residuals  \n",
    "\n",
    "plt.scatter(courseEval['gender_dummy'], residuals)\n",
    "plt.xlabel(\"gender_dummy\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.title(\"residuals vs gender_dummy\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print_question(5)\n",
    "\n",
    "print(\"For Residuals vs. predictions, The dots appear rather scattered.\")\n",
    "print(\"There is also a feeling that the dots are a little clustered at the bottom, so maybe it's not completely random.\")\n",
    "print()\n",
    "print(\"For Histogram of residuals,It is high in the middle and low at both ends \")\n",
    "print(\"with a bell-curve-like shape, but slightly biased to the right.\")\n",
    "print()\n",
    "print(\"For QQ plot, \")\n",
    "print(\"The dots were roughly in line with the lines, so the regularity is probably OK.\")\n",
    "print(\"But the edges are a bit crooked.\")\n",
    "print()\n",
    "\n",
    "print(\"For Residuals vs order of collection, \")\n",
    "print(\"They were scattered discretely up and down and no distinctive patterns (like rightward direction) were visible\")\n",
    "print(\"The dots seem to be slightly concentrated on the upper side.\")\n",
    "print()\n",
    "\n",
    "print(\"Residuals vs. explanatory variables (bty_avg and gender_dummy),\")\n",
    "print(\"ty_avg is scattered, with no distinctive pattern.\")\n",
    "print(\"The gender_dummy is just a complete split of points into 0s and 1s.\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8a8fc",
   "metadata": {
    "colab_type": "text",
    "id": "cifZd7EzmNTx"
   },
   "source": [
    "### The search for the best model \n",
    "Now we will incorporate more predictors into the regression model. We will start with a full model that predicts professor score based on  ethnicity, gender, language of the university where they got their degree (language), age, proportion of students that filled out evaluations (cls_perc_eval), class size (cls_students), course level (cls_level), number of professors (cls_profs), number of credits (cls_credits), average beauty rating (bty_avg), outfit (pic_outfit), and picture color (pic_color)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a046cf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "DHN5_vz9mRgY",
    "outputId": "2f3e1034-745b-4aa6-bb70-48d9f6e8f21a"
   },
   "outputs": [],
   "source": [
    "m_full = sm.formula.ols(formula = 'score ~ ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_profs + cls_credits + bty_avg + pic_outfit + pic_color', data = courseEval)\n",
    "multi_reg = m_full.fit()\n",
    "print(multi_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972da30f",
   "metadata": {
    "colab_type": "text",
    "id": "LInSO69omkGb"
   },
   "source": [
    "## Exercise 5\n",
    "Interpret the coefficient associated with the ethnicity variable.<div style=\"text-align: right\"> **2 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0100dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_question(1)\n",
    "\n",
    "m = sm.formula.ols(formula='score ~ ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_profs + cls_credits + bty_avg + pic_outfit + pic_color', data=courseEval)\n",
    "fitted_model = m.fit()\n",
    "\n",
    "\n",
    "print(fitted_model.summary())\n",
    "\n",
    "print(fitted_model.params)\n",
    "\n",
    "for name in fitted_model.params.index:\n",
    "    if 'ethnicity' in name:\n",
    "        print(f\"name is {name}\")\n",
    "\n",
    "\n",
    "ethnicity_coef = fitted_model.params['ethnicity[T.not minority]']\n",
    "print(f\"ethnicity[T.not minority] = {ethnicity_coef}\")\n",
    "\n",
    "\n",
    "print(courseEval['ethnicity'].unique())\n",
    "\n",
    "print_question(2)\n",
    "print(f\"Non-minority teachers rated {ethnicity_coef} points higher than minority teachers\")\n",
    "print(\"but this difference may be coincidental (it is not a clear difference).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f3c3d",
   "metadata": {
    "colab_type": "text",
    "id": "JmwWcOfFmlsX"
   },
   "source": [
    "## Exercise 6\n",
    "One of the things that makes multiple regression interesting, but also difficult, is that coefficient estimates depend on the other variables that are included in the model.\n",
    "\n",
    "1. Drop the variable with the largest p-value and re-fit the model. \n",
    "2. Did the coefficients and significance of the other explanatory variables change?  \n",
    "3. What happened to `ethnicity`? Describe and interpret your observations in terms of collinearity with the other explanatory variables.<div style=\"text-align: right\"> **3 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e48d2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1icR44Zn1A2"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "print_question(1)\n",
    "full_formula = (\"score ~ ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_credits + bty_avg + pic_outfit + pic_color + cls_profs \")\n",
    "\n",
    "full_mod  = sm.formula.ols(full_formula, data=courseEval).fit()\n",
    "print(full_mod.summary())\n",
    "\n",
    "\n",
    "worst_variable = full_mod.pvalues.idxmax()\n",
    "print(\"Worst p-Value: \", worst_variable, \"\\n\")\n",
    "\n",
    "excluding_worst = (\"score ~ ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_credits + bty_avg + pic_outfit + pic_color\")\n",
    "excluding_worst_mod  = sm.formula.ols(excluding_worst, data=courseEval).fit()\n",
    "print(excluding_worst_mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf959a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_question(2)\n",
    "for var in full_mod.params.index:\n",
    "    if var in excluding_worst_mod.params.index: # check if the variable is also included in the second\n",
    "        diff = full_mod.params[var] - excluding_worst_mod.params[var] # calc the difference\n",
    "        print(f\"{var:<30} difference = {diff:>6.4f}\") # :<x and :>x to left and right align in x wide space\n",
    "\n",
    "print(50*\"-\")\n",
    "for var in full_mod.params.index:\n",
    "    if var in excluding_worst_mod.params.index: \n",
    "        p_diff = full_mod.pvalues[var] - excluding_worst_mod.pvalues[var]\n",
    "        print(f\"{var:<30} difference = {p_diff:>6.4f}\") \n",
    "\n",
    "print(\"\\nThere are some differences, but they are very small. The highest difference I can observe is -0.0045 for the coefficients and 0.0211 for the p-values.\\nThe minor shifts suggest that removing the variable had a small effect on the estimates or significances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8514ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ethnicity remained statistically insignificant and it only had a small difference in coef (-0.0041) and p-value (+0.0105).\\n\"\n",
    "      \"So we can conclude that it wasn't sharing much with the dropped variable -> ethnicity wasn't strongly entangled with cls_profs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a784f8c",
   "metadata": {
    "colab_type": "text",
    "id": "KDk9QIXymths"
   },
   "source": [
    "## Exercise 7\n",
    "Using backward-selection and p-value as the selection criterion, determine the best model. \n",
    "1. Describe the order in which you removed predictor variables.\n",
    "2. Show the output for the final model. <div style=\"text-align: right\"> **2 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17fe34",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loYH_Vivo1EV"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "current_predictors = ['ethnicity','gender','language','age','cls_perc_eval','cls_students', 'cls_level','cls_profs','cls_credits','bty_avg','pic_outfit','pic_color']\n",
    "removed = []\n",
    "\n",
    "while True:\n",
    "    formula = 'score ~ ' + ' + '.join(current_predictors)\n",
    "    print(formula)\n",
    "    model = sm.formula.ols(formula=formula, data=courseEval).fit()\n",
    "    pvals = model.pvalues.drop('Intercept') #drop intercept, might interfere\n",
    "    worst_term = pvals.idxmax() # get the worst term\n",
    "    if pvals[worst_term] <= 0.05: # if the p value is below 0.05, meaning that it significant, break the loop\n",
    "        break\n",
    "    # print(worst_term) # anoyingly it has the [...] stuff in there\n",
    "    worst_var = worst_term.split('[')[0] # split at \"[\" and take the first element\n",
    "    # print(worst_var)\n",
    "    current_predictors.remove(worst_var) # remove the worst\n",
    "    removed.append(worst_var) # add to the removed list\n",
    "\n",
    "print(\"\\nOrder of variables removed:\", removed)\n",
    "print(\"\\nFinal model:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39222a",
   "metadata": {
    "colab_type": "text",
    "id": "wajRdZ1pm35R"
   },
   "source": [
    "## Exercise 8\n",
    "Verify that the conditions for this reduced, final model are reasonable using diagnostic plots.\n",
    "To get the predicted values for a regression model, you can use the *predict* function in your regression model object, so for the example above question 5 that would be: `predicted_value = multi_reg.predict()`. Make sure you use subplots to order the diagnostic plots in a structured  manner.<div style=\"text-align: right\"> **5 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be2a6d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL19R_KRsyC3"
   },
   "outputs": [],
   "source": [
    "# your code/answer here\n",
    "residuals = model.resid # diff in prediction and observation\n",
    "fitted    = model.predict()\n",
    "abs_res   = np.abs(residuals) # convert to abs\n",
    "\n",
    "# 2×3 grid\n",
    "fig, axs = plt.subplots(4, figsize=(8, 14))\n",
    "\n",
    "\n",
    "axs[0].scatter(fitted, abs_res, s=10)\n",
    "axs[0].set_title('abs residuals vs fitted')\n",
    "axs[0].set_xlabel('fitted')\n",
    "axs[0].set_ylabel('abs residuals')\n",
    "\n",
    "\n",
    "axs[1].hist(residuals, bins=20)\n",
    "axs[1].set_title('histogram residuals')\n",
    "axs[1].set_xlabel('residual')\n",
    "axs[1].set_ylabel('frequency')\n",
    "\n",
    "\n",
    "\n",
    "ss.probplot(residuals, dist=\"norm\", plot=axs[2])\n",
    "axs[2].set_title('qq plot')\n",
    "\n",
    "\n",
    "axs[3].scatter(range(len(residuals)), residuals, s=10)\n",
    "axs[3].set_title('residuals vs order')\n",
    "axs[3].set_xlabel('observation')\n",
    "axs[3].set_ylabel('residual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Abs residuals vs fitted doesn't have a funnel or megaphone shape so it seems to be linear with constant variance\")\n",
    "print(\"The histogram has a negative skew\")\n",
    "print(\"The qq plot also the negative skew in the histogram\")\n",
    "print(\"Looks like random scatter around 0 without significant drift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e9a46",
   "metadata": {
    "colab_type": "text",
    "id": "9WBbN6JOreV7"
   },
   "source": [
    "## Exercise 9\n",
    "In Exercises 4 and 8, we looked at residuals through histograms and probability plotes, and we were wondering if they are actually normally distributed. In both cases we were unsure whether the residuals may deviate too much from normality. Non-normality of residuals is not a problem *per se* for linear regression but it can be problematic for inference (i.e., deriving and interpreting p-values). Several formal tests exist that can tell us whether residuals are normally distributed, or not. One such test is the Shapiro-Wilk test, another one is the Kolmogorov-Smirnov test.\n",
    "\n",
    "1. Run the Shapiro-Wilk test from `scipy.stats` on the residuals from the previous exercise.\n",
    "2. Are the residuals normally distributed according to this test? Interpret the test output.<div style=\"text-align: right\"> **2 points** </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86769d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, p_value = ss.shapiro(residuals)\n",
    "print(f\"Shapiro–Wilk test: W = {W:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "\n",
    "print(\"No, they are not normally distributed because the p-value is below 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d55c3",
   "metadata": {
    "colab_type": "text",
    "id": "6wD7kf3MuyfT"
   },
   "source": [
    "## Exercise 10\n",
    "1. Based on your final model, describe the characteristics of a professor and course at University of Texas at Austin that would be associated with a high evaluation score. \n",
    "2. Would you be comfortable generalizing your conclusions to apply to professors generally (at any university)? Justify your answer.<div style=\"text-align: right\"> **2 points** </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487db841",
   "metadata": {},
   "source": [
    "Characteristics:\n",
    "- Not minority ethnicity\n",
    "- Male\n",
    "- English speaking\n",
    "- Teaches a one credit course\n",
    "- Uses a non color profile picture\n",
    "- Young\n",
    "- Teaches a class where many students submitted a evaluation\n",
    "- And has a high beauty score\n",
    "\n",
    "I would not be comfortable generalizing my conclusions. It is only one specific university in one specific region during one specific time. Beauty ideals could change, grading policies might differ,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a9594",
   "metadata": {},
   "source": [
    "**Total number of points**: 36"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "spyder",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
